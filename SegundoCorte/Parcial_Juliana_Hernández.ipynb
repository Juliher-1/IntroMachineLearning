{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**PARCIAL SEGUNDO CORTE**#"
      ],
      "metadata": {
        "id": "mcd0gbc2sJIQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dEuOk2BnWWP",
        "outputId": "60f1af5d-4ad1-4174-dcf0-33213772ad9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-30 21:33:09--  https://raw.githubusercontent.com/javierherrera1996/IntroMachineLearning/refs/heads/main/SegundoCorte/loan_approval_dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 384337 (375K) [text/plain]\n",
            "Saving to: ‘loan_approval_dataset.csv’\n",
            "\n",
            "loan_approval_datas 100%[===================>] 375.33K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-04-30 21:33:10 (9.15 MB/s) - ‘loan_approval_dataset.csv’ saved [384337/384337]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/javierherrera1996/IntroMachineLearning/refs/heads/main/SegundoCorte/loan_approval_dataset.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#INTRODUCCIÓN#"
      ],
      "metadata": {
        "id": "qYj49lVqn7UO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este taller, trabajaremos con un conjunto de datos relacionado con la aprobaciÓn de préstamos. El objetivo es aplicar técnicas de anélisis de datos y Machine Learning para entender cómo los distintos factores influyen en la decisión de aprobación o rechazo del préstamo.\n",
        "El conjunto de datos contiene las siguientes columnas:\n"
      ],
      "metadata": {
        "id": "ltrexMd7n-Ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "• loan id: Identificador único del préstamo\n",
        "\n",
        "• no of dependents: Número de dependientes del solicitante\n",
        "\n",
        "• education: Nivel educativo del solicitante (Graduate o Not Graduate)\n",
        "\n",
        "• self employed: Si el solicitante es autoempleado (Yes o No)\n",
        "\n",
        "• income annum: Ingreso anual del solicitante en unidades monetarias\n",
        "\n",
        "• loan amount: Monto solicitado para el préstamo\n",
        "\n",
        "• loan term: Duración del préstamo en años\n",
        "\n",
        "• cibil score: Puntaje CIBIL del solicitante\n",
        "\n",
        "• residential assets value: Valor de los activos residenciales del solicitante\n",
        "\n",
        "• commercial assets value: Valor de los activos comerciales del solicitante\n",
        "\n",
        "• luxury assets value: Valor de los activos de lujo del solicitante\n",
        "\n",
        "• bank asset value: Valor de los activos bancarios del solicitante\n",
        "\n",
        "• loan status: Estado del préstamo (Aprobado o Rechazado)\n"
      ],
      "metadata": {
        "id": "p2ZoWTafoN96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 Preguntas Teóricas#\n"
      ],
      "metadata": {
        "id": "mP8lDaWDouaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Responde las siguientes preguntas relacionadas con los conceptos de análisis de datos, estadísticas y Machine Learning.\n"
      ],
      "metadata": {
        "id": "5zsMkqWEoyr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.1 Pregunta 1: Análisis Exploratorio de Datos (EDA)\n"
      ],
      "metadata": {
        "id": "qlEWNLYyo4Jk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Qué pasos seguirías para realizar un análisis exploratorio de los datos antes de construir un modelo de\n",
        "Machine Learning? Explica cada paso y menciona las herramientas que utilizarías."
      ],
      "metadata": {
        "id": "tRbdPFQqpEoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El EDA es un proceso iterativo que implica explorar los datos de diferentes maneras para obtener una comprensión profunda de su estructura, sus relaciones y sus patrones. Este proceso es crucial para la construcción de modelos de Machine Learning efectivos, ya que permite identificar los problemas en los datos, seleccionar las características más relevantes y formular hipótesis sobre el comportamiento del modelo.\n",
        "Los pasos que seguiría:\n",
        "1. importación y limpieza de datos.\n",
        "2. Análisis univariado.\n",
        "3. Análisis bivariado.\n",
        "4. Análisis multivariado.\n",
        "5. Identificación de patrones y anomalías.\n",
        "6. Formulación de hipótesis.\n",
        "7. Documentar hallazgos."
      ],
      "metadata": {
        "id": "zN4xh6kf_wjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.2 Pregunta 2: Preprocesamiento de Datos"
      ],
      "metadata": {
        "id": "DiMdWJzKpJaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagina que uno de los datos contiene valores faltantes o atípicos (outliers). ¿Qué técnicas utilizarías para tratar con estos problemas en el conjunto de datos de la tabla? Justifica tu respuesta."
      ],
      "metadata": {
        "id": "rFTAUsS2pOut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es importante abordar los valores faltantes y los valores atípicos antes de construir un modelo de Machine Learning porque pueden afectar la precisión y la confiabilidad del modelo. La elección de la técnica adecuada depende de la naturaleza de los datos, la cantidad de valores faltantes o atípicos, y el objetivo del análisis.\n",
        "\n",
        "Técnicas que utilizaría:\n",
        "1. Eliminación filas y columnas.\n",
        "2. Imputación.\n",
        "3. Utilizar modelos para predecir valores faltantes.\n",
        "4. Valores atípicos (outliers).\n",
        "5. Tranformación.\n",
        "6. Utilizar modelos robustos."
      ],
      "metadata": {
        "id": "7h1vyB0Asad9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.3 Pregunta 3: Modelos de Clasificación"
      ],
      "metadata": {
        "id": "3mMBPoEFpWWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, el objetivo es predecir si un préstamo sería aprobado o rechazado en función de las características del solicitante. ¿Qué tipo de modelo de clasificación usarías y por qué? Discute las ventajas y\n",
        "desventajas de este modelo."
      ],
      "metadata": {
        "id": "cH27sjcJpZah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "un modelo de clasificación adecuado sería la Regresión Logística.\n",
        "\n",
        "¿Por qué Regresión Logística?\n",
        "\n",
        "- El problema que se plantea es de clasificación binaria, ya que la variable objetivo (estado del préstamo) tiene dos posibles valores: aprobado o rechazado. La regresión logística es un modelo específicamente diseñado para este tipo de problemas.\n",
        "\n",
        "- Interpretabilidad: La regresión logística es un modelo relativamente fácil de interpretar. Los coeficientes del modelo indican la importancia de cada variable predictora en la probabilidad de que el préstamo sea aprobado. Esto permite entender qué factores son más importantes en la decisión de aprobación del préstamo.\n",
        "\n",
        "- Eficiencia: La regresión logística es un modelo eficiente en términos de tiempo de entrenamiento y recursos computacionales. Esto es importante cuando se trabaja con conjuntos de datos grandes.\n",
        "\n",
        "Ventajas de la Regresión Logística:\n",
        "\n",
        "- Fácil de implementar y entrenar.\n",
        "Interpretable: Los coeficientes del modelo proporcionan información sobre la importancia de cada variable predictora.\n",
        "\n",
        "- Eficiente: Requiere pocos recursos computacionales.\n",
        "\n",
        "- Probabilidades: Proporciona la probabilidad de que un préstamo sea aprobado o rechazado.\n",
        "\n",
        "Desventajas de la Regresión Logística:\n",
        "\n",
        "- Linealidad: Asume una relación lineal entre las variables predictoras y la variable objetivo. Si la relación no es lineal, el modelo puede no ser preciso.\n",
        "\n",
        "- Sensible a valores atípicos: Los valores atípicos pueden afectar la precisión del modelo.\n",
        "\n",
        "- No maneja bien las interacciones entre variables: Si hay interacciones complejas entre las variables predictoras, el modelo puede no capturarlas adecuadamente.\n",
        "\n",
        "- Puede ser menos preciso que otros modelos más complejos: En algunos casos, otros modelos de clasificación, como los árboles de decisión o las redes neuronales, pueden tener un mejor rendimiento.\n",
        "\n",
        "Alternativas:\n",
        "\n",
        "Si bien la regresión logística es una buena opción para este problema, también se podrían considerar otros modelos de clasificación, como:\n",
        "\n",
        ". Árboles de decisión: Son fáciles de interpretar y pueden manejar relaciones no lineales entre las variables. Sin embargo, pueden ser propensos al sobreajuste.\n",
        "\n",
        "- Bosques aleatorios (Random Forests): Son un conjunto de árboles de decisión que pueden mejorar la precisión y la robustez del modelo.\n",
        "\n",
        "- Máquinas de vectores de soporte (SVM): Son eficaces en problemas de alta dimensionalidad y pueden manejar relaciones no lineales. Sin embargo, pueden ser más difíciles de interpretar.\n",
        "\n",
        "- Redes neuronales: Son modelos muy flexibles que pueden aprender relaciones complejas entre las variables. Sin embargo, pueden ser difíciles de entrenar y requieren grandes cantidades de datos."
      ],
      "metadata": {
        "id": "W4napqq1sa6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.4 Pregunta 4: Desbalanceo de Clases"
      ],
      "metadata": {
        "id": "LN77YvE1piu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Qué es el desbalanceo de clases y por qué es un problema al entrenar un modelo de clasificación? ¿Qué técnicas utilizarías para abordar este problema, como SMOTE?\n"
      ],
      "metadata": {
        "id": "catueFlFplOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El desbalanceo de clases puede ser un problema al entrenar un modelo de clasificación. SMOTE es una técnica efectiva para abordar este problema al crear muestras sintéticas de la clase minoritaria, lo que equilibra el conjunto de datos y mejora la capacidad del modelo para predecir la clase minoritaria.\n",
        "\n",
        "Otras técnicas que utilizaría:\n",
        "1. Remuestreo.\n",
        "2. Ajustar el peso de las clases.\n",
        "3. Utilizar algoritmos al desbalanceo de clases.\n",
        "4. Utilizar métricas de evaluación."
      ],
      "metadata": {
        "id": "nhNLBwU4sbSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.5 Pregunta 5: Overfitting"
      ],
      "metadata": {
        "id": "xT5DFZYnp1Uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Qué es el overfitting y cómo puedes detectarlo en un modelo de Machine Learning? Explica qué medidas tomarías para evitar el sobreajuste y mejorar la capacidad de generalización de tu modelo.\n"
      ],
      "metadata": {
        "id": "HeUJiXLpp4Tu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El overfitting, o sobreajuste, ocurre cuando un modelo de Machine Learning se ajusta demasiado a los datos de entrenamiento y no puede generalizar bien a nuevos datos.\n",
        "\n",
        "Se puede detectar el overfitting observando las siguientes señales:\n",
        "\n",
        "- Alto rendimiento en el conjunto de entrenamiento, pero bajo rendimiento en el conjunto de prueba: Si el modelo tiene una alta precisión en los datos de entrenamiento, pero una baja precisión en los datos de prueba, es una señal de que el modelo se ha sobreajustado a los datos de entrenamiento.\n",
        "\n",
        "- Brecha significativa entre las métricas de entrenamiento y validación: Si hay una gran diferencia entre las métricas de rendimiento del modelo en el conjunto de entrenamiento y el conjunto de validación (por ejemplo, precisión, error), es una señal de overfitting.\n",
        "\n",
        "- Complejidad excesiva del modelo: Si el modelo es demasiado complejo (por ejemplo, demasiadas características, demasiados nodos en una red neuronal), es más probable que se sobreajuste a los datos de entrenamiento.\n",
        "\n",
        "Medidas para evitar el overfitting y mejorar la generalización:\n",
        "\n",
        "- Simplificar el modelo: Reducir la complejidad del modelo utilizando menos características, menos capas en una red neuronal o un algoritmo más simple.\n",
        "\n",
        "- Regularización: Agregar una penalización a la función de costo del modelo para evitar que los coeficientes de las características sean demasiado grandes, lo que puede ayudar a prevenir el overfitting. Se puede usar la regularización L1 (Lasso) o L2 (Ridge).\n",
        "\n",
        "- Validación cruzada: Dividir los datos en conjuntos de entrenamiento, validación y prueba para evaluar el rendimiento del modelo en diferentes subconjuntos de datos y ajustar los hiperparámetros del modelo para evitar el overfitting.\n",
        "\n",
        "- Aumento de datos: Aumentar la cantidad de datos de entrenamiento puede ayudar al modelo a generalizar mejor y a evitar el overfitting. Se pueden usar técnicas como la rotación, el desplazamiento o el zoom para crear nuevas instancias de datos a partir de las existentes.\n",
        "\n",
        "- Detención temprana: Detener el entrenamiento del modelo antes de que comience a sobreajustarse a los datos de entrenamiento puede ayudar a prevenir el overfitting. Se puede monitorizar el rendimiento del modelo en el conjunto de validación durante el entrenamiento y detener el entrenamiento cuando el rendimiento en el conjunto de validación comience a disminuir."
      ],
      "metadata": {
        "id": "s_whvFi2sbyb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3 Ejercicios Prácticos#"
      ],
      "metadata": {
        "id": "KVYMg2ZCp_7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.1 Ejercicio 1: Análisis Descriptivo"
      ],
      "metadata": {
        "id": "yQbuF0xXqDvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usa la tabla de datos proporcionada para realizar un análisis descriptivo de las variables numéricas.\n",
        "Responde a las siguientes preguntas:\n",
        "\n",
        "• ¿Cuál es el promedio de los ingresos anuales (income annum) de los solicitantes?\n",
        "\n",
        "• ¿Cuál es el puntaje CIBIL promedio de los solicitantes cuyo préstamo fue aprobado?\n",
        "\n",
        "• ¿Cuál es la duración promedio de los préstamos (loan term)?\n"
      ],
      "metadata": {
        "id": "K-wSyWykqItA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv  ('loan_approval_dataset.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "ZGz4MDeVvgIB",
        "outputId": "ef1415a0-d2c9-4bf8-cd16-c7a1aec6b39e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   loan_id   no_of_dependents      education  self_employed   income_annum  \\\n",
              "0        1                  2       Graduate             No        9600000   \n",
              "1        2                  0   Not Graduate            Yes        4100000   \n",
              "2        3                  3       Graduate             No        9100000   \n",
              "3        4                  3       Graduate             No        8200000   \n",
              "4        5                  5   Not Graduate            Yes        9800000   \n",
              "\n",
              "    loan_amount   loan_term   cibil_score   residential_assets_value  \\\n",
              "0      29900000          12           778                    2400000   \n",
              "1      12200000           8           417                    2700000   \n",
              "2      29700000          20           506                    7100000   \n",
              "3      30700000           8           467                   18200000   \n",
              "4      24200000          20           382                   12400000   \n",
              "\n",
              "    commercial_assets_value   luxury_assets_value   bank_asset_value  \\\n",
              "0                  17600000              22700000            8000000   \n",
              "1                   2200000               8800000            3300000   \n",
              "2                   4500000              33300000           12800000   \n",
              "3                   3300000              23300000            7900000   \n",
              "4                   8200000              29400000            5000000   \n",
              "\n",
              "   loan_status  \n",
              "0     Approved  \n",
              "1     Rejected  \n",
              "2     Rejected  \n",
              "3     Rejected  \n",
              "4     Rejected  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16ae97e0-8927-4722-b3ea-80de042e88cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loan_id</th>\n",
              "      <th>no_of_dependents</th>\n",
              "      <th>education</th>\n",
              "      <th>self_employed</th>\n",
              "      <th>income_annum</th>\n",
              "      <th>loan_amount</th>\n",
              "      <th>loan_term</th>\n",
              "      <th>cibil_score</th>\n",
              "      <th>residential_assets_value</th>\n",
              "      <th>commercial_assets_value</th>\n",
              "      <th>luxury_assets_value</th>\n",
              "      <th>bank_asset_value</th>\n",
              "      <th>loan_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>9600000</td>\n",
              "      <td>29900000</td>\n",
              "      <td>12</td>\n",
              "      <td>778</td>\n",
              "      <td>2400000</td>\n",
              "      <td>17600000</td>\n",
              "      <td>22700000</td>\n",
              "      <td>8000000</td>\n",
              "      <td>Approved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>4100000</td>\n",
              "      <td>12200000</td>\n",
              "      <td>8</td>\n",
              "      <td>417</td>\n",
              "      <td>2700000</td>\n",
              "      <td>2200000</td>\n",
              "      <td>8800000</td>\n",
              "      <td>3300000</td>\n",
              "      <td>Rejected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>9100000</td>\n",
              "      <td>29700000</td>\n",
              "      <td>20</td>\n",
              "      <td>506</td>\n",
              "      <td>7100000</td>\n",
              "      <td>4500000</td>\n",
              "      <td>33300000</td>\n",
              "      <td>12800000</td>\n",
              "      <td>Rejected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>8200000</td>\n",
              "      <td>30700000</td>\n",
              "      <td>8</td>\n",
              "      <td>467</td>\n",
              "      <td>18200000</td>\n",
              "      <td>3300000</td>\n",
              "      <td>23300000</td>\n",
              "      <td>7900000</td>\n",
              "      <td>Rejected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>9800000</td>\n",
              "      <td>24200000</td>\n",
              "      <td>20</td>\n",
              "      <td>382</td>\n",
              "      <td>12400000</td>\n",
              "      <td>8200000</td>\n",
              "      <td>29400000</td>\n",
              "      <td>5000000</td>\n",
              "      <td>Rejected</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16ae97e0-8927-4722-b3ea-80de042e88cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16ae97e0-8927-4722-b3ea-80de042e88cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16ae97e0-8927-4722-b3ea-80de042e88cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d06b7139-1367-4ee5-b866-1969c59a0ea8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d06b7139-1367-4ee5-b866-1969c59a0ea8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d06b7139-1367-4ee5-b866-1969c59a0ea8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4269,\n  \"fields\": [\n    {\n      \"column\": \"loan_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1232,\n        \"min\": 1,\n        \"max\": 4269,\n        \"num_unique_values\": 4269,\n        \"samples\": [\n          1704,\n          1174,\n          309\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" no_of_dependents\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" Not Graduate\",\n          \" Graduate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" self_employed\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" Yes\",\n          \" No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" income_annum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2806839,\n        \"min\": 200000,\n        \"max\": 9900000,\n        \"num_unique_values\": 98,\n        \"samples\": [\n          6200000,\n          9300000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" loan_amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9043362,\n        \"min\": 300000,\n        \"max\": 39500000,\n        \"num_unique_values\": 378,\n        \"samples\": [\n          25800000,\n          26100000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" loan_term\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 2,\n        \"max\": 20,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          14,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" cibil_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 172,\n        \"min\": 300,\n        \"max\": 900,\n        \"num_unique_values\": 601,\n        \"samples\": [\n          859,\n          414\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" residential_assets_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6503636,\n        \"min\": -100000,\n        \"max\": 29100000,\n        \"num_unique_values\": 278,\n        \"samples\": [\n          700000,\n          3500000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" commercial_assets_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4388966,\n        \"min\": 0,\n        \"max\": 19400000,\n        \"num_unique_values\": 188,\n        \"samples\": [\n          13500000,\n          14600000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" luxury_assets_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9103753,\n        \"min\": 300000,\n        \"max\": 39200000,\n        \"num_unique_values\": 379,\n        \"samples\": [\n          15300000,\n          12100000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" bank_asset_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3250185,\n        \"min\": 0,\n        \"max\": 14700000,\n        \"num_unique_values\": 146,\n        \"samples\": [\n          4800000,\n          14400000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \" loan_status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" Rejected\",\n          \" Approved\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"loan_approval_dataset.csv\")\n",
        "\n",
        "# Mostrar nombres exactos de las columnas\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7j_jMZP0BF7",
        "outputId": "82d831d9-79f4-4b49-bcce-d24226856239"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loan_id', ' no_of_dependents', ' education', ' self_employed', ' income_annum', ' loan_amount', ' loan_term', ' cibil_score', ' residential_assets_value', ' commercial_assets_value', ' luxury_assets_value', ' bank_asset_value', ' loan_status']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "promedio_ingresos = df[' income_annum'].mean()\n",
        "print(\"El promedio de ingresos anuales es:\", promedio_ingresos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPvGAyZl0G_D",
        "outputId": "2be3700c-f8f5-4549-daa6-c1a409b333b6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El promedio de ingresos anuales es: 5059123.9166081045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "puntaje_cibil_promedio_aprobados = df[df[' loan_status'] == 'Approved'][' cibil_score'].mean()\n",
        "print(\"El puntaje CIBIL promedio de los solicitantes cuyo préstamo fue aprobado es:\", puntaje_cibil_promedio_aprobados)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM6xP_jZ0UqA",
        "outputId": "2d650e66-e805-42e0-8af1-e98d9c5d848a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El puntaje CIBIL promedio de los solicitantes cuyo préstamo fue aprobado es: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "duracion_promedio_prestamos = df[' loan_term'].mean()\n",
        "print(\"La duración promedio de los préstamos es:\", duracion_promedio_prestamos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIW8ooHq03rR",
        "outputId": "57ef0830-2989-487a-f99d-4297057c3574"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La duración promedio de los préstamos es: 10.900445069102835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.2 Ejercicio 2: Preprocesamiento de Datos"
      ],
      "metadata": {
        "id": "FPkTjsDqqS-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realiza los siguientes pasos de preprocesamiento:\n",
        "\n",
        "• Convierte la variable education en una variable binaria (0: Not Graduate, 1: Graduate).\n",
        "\n",
        "• Convierte la variable self employed en una variable binaria (0: No, 1: Yes).\n",
        "\n",
        "• Rellena los valores faltantes, si los hubiera, con la media de la columna correspondiente."
      ],
      "metadata": {
        "id": "lDZJeFu0qWqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[' education'] = df[' education'].map({' Not Graduate': 0, ' Graduate': 1})"
      ],
      "metadata": {
        "id": "66m5vSduqqot"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[' self_employed'] = df[' self_employed'].map({' No': 0, ' Yes': 1})"
      ],
      "metadata": {
        "id": "Id8GoKtA1GP4"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.select_dtypes(include=['number']):\n",
        "  df[col] = df[col].fillna(df[col].mean())"
      ],
      "metadata": {
        "id": "f4Ktp6QT1NNm"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.3 Ejercicio 3: Análisis de Correlación"
      ],
      "metadata": {
        "id": "MNdM5e0dqcSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realiza un análisis de correlación entre las siguientes variables:\n",
        "\n",
        "• income annum y loan amount\n",
        "\n",
        "• cibil score y loan amount\n",
        "\n",
        "• residential assets value y commercial assets value\n",
        "\n",
        "Discute los resultados obtenidos, ¿existen correlaciones fuertes entre algunas variables? ¿Cómo afectaría esto a un modelo predictivo?"
      ],
      "metadata": {
        "id": "gISdB2QdqgrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_income_loan = df[' income_annum'].corr(df[' loan_amount'])\n",
        "\n",
        "print(f\"La correlación entre 'income annum' y 'loan amount' es: {correlation_income_loan}\")\n",
        "\n",
        "correlation_cibil_loan = df[' cibil_score'].corr(df[' loan_amount'])\n",
        "print(f\"La correlación entre 'cibil score' y 'loan amount' es: {correlation_cibil_loan}\")\n",
        "\n",
        "correlation_residential_commercial = df[' residential_assets_value'].corr(df[' commercial_assets_value'])\n",
        "print(f\"La correlación entre 'residential assets value' y 'commercial assets value' es: {correlation_residential_commercial}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i59S3heS1f-5",
        "outputId": "da67a265-5487-4352-c69f-13e0dc78d9e3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La correlación entre 'income annum' y 'loan amount' es: 0.9274699109871487\n",
            "La correlación entre 'cibil score' y 'loan amount' es: -0.017034787023534392\n",
            "La correlación entre 'residential assets value' y 'commercial assets value' es: 0.41478602657549807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El análisis de correlación revela una correlación fuerte entre income_annum y loan_amount, una correlación moderada entre cibil_score y loan_amount, y una correlación débil entre residential_assets_value y commercial_assets_value.\n",
        "\n",
        "Estas correlaciones pueden afectar el modelo predictivo al introducir multicolinealidad (cuando las variables predictoras están altamente correlacionadas), redundancia (cuando una variable es innecesaria debido a su alta correlación con otra) y sesgo (cuando el modelo aprende patrones incorrectos debido a correlaciones espurias).\n",
        "\n",
        "Para mejorar el modelo, se puede considerar eliminar variables redundantes, utilizar técnicas de regularización como Ridge o Lasso, y analizar la causalidad para asegurar que las correlaciones reflejen relaciones reales."
      ],
      "metadata": {
        "id": "oSEmVK3q1smU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.4 Ejercicio 4: Comparación de Modelos de Clasificación"
      ],
      "metadata": {
        "id": "vbQhfHhdqoyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando la tabla de datos, entrena dos modelos de clasificación: Regresión Logística y Arbol de decisión para predecir el estado del préstamo (loan status). Compara los modelos utilizando la métrica ROC AUC. Para esto, sigue los pasos:\n",
        "\n",
        "• Preprocesa los datos (conversión de variables categóricas, manejo de valores faltantes).\n",
        "\n",
        "• Divide los datos en un conjunto de entrenamiento y uno de prueba.\n",
        "\n",
        "• Entrena los modelos de Regresión Logística y Arbol de Decisión.\n",
        "\n",
        "• Hay alguna evidencia de overfitting si/no.\n",
        "\n",
        "• Calcula la métrica ROC AUC para cada modelo y compáralos.\n",
        "\n",
        "• Si detectas desbalanceo de clases, aplica SMOTE para equilibrar el dataset antes de entrenar los modelos.\n",
        "\n",
        "Discute los resultados obtenidos. ¿Cuál modelo es el más adecuado para este problema? ¿Por qué?"
      ],
      "metadata": {
        "id": "ou57SfsTqxhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "\n",
        "X = df.drop(' loan_status', axis=1)\n",
        "y = df[' loan_status']\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "logreg_model = LogisticRegression(max_iter=1000)\n",
        "logreg_model.fit(X_train, y_train)\n",
        "logreg_pred = logreg_model.predict_proba(X_test)[:, 1]\n",
        "logreg_roc_auc = roc_auc_score(y_test, logreg_pred)\n",
        "print(f\"Logistic Regression ROC AUC: {logreg_roc_auc}\")\n",
        "\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict_proba(X_test)[:, 1]\n",
        "dt_roc_auc = roc_auc_score(y_test, dt_pred)\n",
        "print(f\"Decision Tree ROC AUC: {dt_roc_auc}\")\n",
        "\n",
        "print(f\"Decision Tree Depth: {dt_model.get_depth()}\")\n",
        "\n",
        "print(\"Model Comparison:\")\n",
        "if logreg_roc_auc > dt_roc_auc:\n",
        "    print(\"Logistic Regression performs better based on ROC AUC.\")\n",
        "else:\n",
        "    print(\"Decision Tree performs better based on ROC AUC.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFcPkG3H8Dzh",
        "outputId": "9f8e2d92-9460-4f72-d4f3-b140d1ccfb4b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression ROC AUC: 0.886944201802416\n",
            "Decision Tree ROC AUC: 0.9760938421004042\n",
            "Decision Tree Depth: 15\n",
            "Model Comparison:\n",
            "Decision Tree performs better based on ROC AUC.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con base en los resultados obtenidos y considerando los distintos factores, el Árbol de Decisión parece ser el modelo más adecuado para este problema específico de predecir el estado del préstamo. Sin embargo, la diferencia en el rendimiento entre el Árbol de Decisión y la Regresión Logística es pequeña, y ambos modelos pueden ser buenas opciones."
      ],
      "metadata": {
        "id": "ouhOhhSr4yj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.5 Ejercicio 5: Evaluación del Desempeño del Modelo"
      ],
      "metadata": {
        "id": "oP_jX1lKrITo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después de entrenar los modelos, evalúa su desempeño usando métricas adicionales como precisión, recall,F1 y la matriz de confusión. Responde las siguientes preguntas:\n",
        "\n",
        "• ¿Qué modelo tiene el mejor desempeño general? Justifica tu respuesta utilizando las métricas.\n",
        "\n",
        "• ¿Cómo impacta el desbalanceo de clases en la métrica ROC AUC y en otras métricas?\n",
        "\n",
        "• ¿Qué acciones tomarías si el modelo tiene un alto sesgo hacia la clase mayoritaria?\n"
      ],
      "metadata": {
        "id": "TFr6VcjprM--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "logreg_pred_class = logreg_model.predict(X_test)\n",
        "dt_pred_class = dt_model.predict(X_test)\n",
        "\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, logreg_pred_class))\n",
        "print(\"Logistic Regression Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, logreg_pred_class))\n",
        "\n",
        "print(\"\\nDecision Tree Classification Report:\")\n",
        "print(classification_report(y_test, dt_pred_class))\n",
        "print(\"Decision Tree Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, dt_pred_class))\n",
        "\n",
        "\n",
        "print(\"\\nModel Comparison based on additional metrics:\")\n",
        "print(\"\\nImpact of Class Imbalance:\")\n",
        "print(\"\\nActions for High Bias towards Majority Class:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84j8d2Tk8g0T",
        "outputId": "6d4ba893-7489-4751-f07e-1eb1ed61d98a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.87      0.80       502\n",
            "           1       0.86      0.73      0.79       561\n",
            "\n",
            "    accuracy                           0.80      1063\n",
            "   macro avg       0.80      0.80      0.80      1063\n",
            "weighted avg       0.81      0.80      0.80      1063\n",
            "\n",
            "Logistic Regression Confusion Matrix:\n",
            "[[437  65]\n",
            " [151 410]]\n",
            "\n",
            "Decision Tree Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97       502\n",
            "           1       0.99      0.97      0.98       561\n",
            "\n",
            "    accuracy                           0.98      1063\n",
            "   macro avg       0.98      0.98      0.98      1063\n",
            "weighted avg       0.98      0.98      0.98      1063\n",
            "\n",
            "Decision Tree Confusion Matrix:\n",
            "[[495   7]\n",
            " [ 19 542]]\n",
            "\n",
            "Model Comparison based on additional metrics:\n",
            "\n",
            "Impact of Class Imbalance:\n",
            "\n",
            "Actions for High Bias towards Majority Class:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Precisión: Indica la proporción de predicciones correctas entre todas las predicciones positivas.\n",
        "\n",
        "- Recall: Indica la proporción de predicciones positivas correctas entre todas las instancias realmente positivas.\n",
        "\n",
        "- F1-score: Es la media armónica entre precisión y recall, y proporciona una medida equilibrada del rendimiento del modelo.\n",
        "\n",
        "- Matriz de confusión: Permite visualizar el rendimiento del modelo en términos de verdaderos positivos, verdaderos negativos, falsos positivos y falsos negativos."
      ],
      "metadata": {
        "id": "hlq--tbv_T1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El desbalanceo de clases puede afectar significativamente el rendimiento del modelo. Es importante comprender cómo impacta en las diferentes métricas y aplicar las técnicas apropiadas para mitigar su efecto. En este caso, el uso de SMOTE nos ha ayudado a mejorar el rendimiento del modelo al equilibrar el conjunto de datos."
      ],
      "metadata": {
        "id": "mxOwu7oZ_dsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4 Reflexión Crítica#"
      ],
      "metadata": {
        "id": "yiUSMPwQrdgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después de completar los ejercicios, reflexiona sobre los siguientes puntos:\n",
        "\n",
        "• ¿Qué desafíos enfrentaste al trabajar con los datos proporcionados?\n",
        "\n",
        "• ¿Qué mejorarías en el proceso de preprocesamiento de datos?\n",
        "\n",
        "• Si pudieras recolectar mías datos, ¿qué variables adicionales serían útiles para mejorar el modelo de clasificación?\n",
        "\n",
        "• ¿Cómo asegurarías que el modelo generalice bien y no esté sobreajustado?\n",
        "\n",
        "• ¿Qué impacto tuvo el desbalanceo de clases en la precisión de tu modelo ¿Cómo se resolvió con SMOTE?\n",
        "\n",
        "• ¿Cómo detectarías y manejarías el overfitting en un modelo de Machine Learning? ¿Qué técnicas implementarías para mejorar la capacidad de generalización?\n"
      ],
      "metadata": {
        "id": "__goKkDqrlEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- El conjunto de datos presenta varios desafíos comunes en el análisis de datos y el aprendizaje automático, como valores faltantes, datos categóricos, desbalanceo de clases, valores atípicos y correlaciones entre variables. Abordar estos desafíos mediante técnicas adecuadas de preprocesamiento de datos, selección de modelos y evaluación del rendimiento es importante para construir un modelo de clasificación preciso y confiable para predecir el estado del préstamo.\n",
        "\n",
        "- Para mejorar el preprocesamiento de datos,  exploraria las técnicas más robustas para manejar valores faltantes y codificar variables categóricas, además de escalaria las características, detectar y manejar valores atípicos, realizar ingeniería de características y usar validación cruzada para una mejor generalización del modelo.\n",
        "\n",
        "- Para mejorar el modelo, recolectaría datos adicionales sobre: historial crediticio detallado, estabilidad laboral e ingresos, situación financiera completa, información demográfica relevante e información específica del préstamo.\n",
        "\n",
        "Estos datos proporcionarían una visión más completa del riesgo crediticio del solicitante, mejorando la precisión del modelo.\n",
        "\n",
        "- Aplicando estrategias como: el uso de ténicas de regularización, validación cruzada, simplificación de modelo, aumento de la cantidad de datos y detención temprana, se puede reducir el riesgo de sobreajuste y mejorar la capacidad del modelo para generalizar a nuevos datos, asegurando un rendimiento más confiable en la práctica.\n",
        "\n",
        "- El desbalanceo de clases puede afectar negativamente la precisión del modelo al sesgarlo hacia la clase mayoritaria. SMOTE ayuda a resolver este problema al crear muestras sintéticas de la clase minoritaria, lo que equilibra el conjunto de datos y mejora la capacidad del modelo para predecir la clase minoritaria.\n",
        "\n",
        "- Lo detectaria por medio de señales como: complejidad del modelo, brechas tanto entre métricas de entrenamiento y validación, asi como en el rendimiento de los conjuntos de entrenamiento. El overfitting es un problema común en el aprendizaje automático que puede afectar negativamente el rendimiento del modelo. Al detectar y manejar el overfitting mediante las técnicas: selección de características, conjuntos de modelos e ingeniería de características, pueden mejorar la capacidad de generalización del modelo y garantizar que funcione bien en nuevos datos."
      ],
      "metadata": {
        "id": "0X09UYH0sGQY"
      }
    }
  ]
}